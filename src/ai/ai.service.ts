import { Injectable, InternalServerErrorException, BadRequestException } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import { InjectModel } from '@nestjs/mongoose';
import { Model } from 'mongoose';
import { randomUUID } from 'crypto';
import { createWriteStream, existsSync, mkdirSync } from 'fs';
import { join } from 'path';
import { promisify } from 'util';
import { pipeline } from 'stream';
import { Media } from '../common/schemas/media.schema';
import { AiGeneration } from '../common/schemas/ai-generation.schema';
import { AiCreditsService } from './ai-credits.service';
import { HttpService } from '@nestjs/axios';
import { lastValueFrom } from 'rxjs';

const pump = promisify(pipeline);

@Injectable()
export class AiService {
  private readonly uploadDir = join(process.cwd(), 'uploads');

  constructor(
    @InjectModel(Media.name) private mediaModel: Model<Media>,
    @InjectModel(AiGeneration.name) private aiGenerationModel: Model<AiGeneration>,
    private httpService: HttpService,
    private configService: ConfigService,
    private aiCreditsService: AiCreditsService,
  ) {
    if (!existsSync(this.uploadDir)) {
      mkdirSync(this.uploadDir, { recursive: true });
    }
  }

  private getApiKey(): string {
    const apiKey = this.configService.get<string>('GPT_LLM_KEY');
    if (!apiKey) {
      throw new InternalServerErrorException('AI API key not configured');
    }
    return apiKey;
  }

  async generateText(
    prompt: string, 
    tone: string = 'professional', 
    length: string = 'medium',
    userId?: string
  ): Promise<{ variants: string[]; generation_id: string; credits_remaining: number }> {
    if (!userId) {
      throw new BadRequestException('User ID is required');
    }

    const generationId = this.generateId();
    const cost = this.aiCreditsService.getCost('text');
    
    // –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –±–∞–ª–∞–Ω—Å
    const hasCredits = await this.aiCreditsService.checkCredits(userId, cost);
    if (!hasCredits) {
      const balance = await this.aiCreditsService.getBalance(userId);
      throw new BadRequestException(
        `Insufficient AI credits. You have ${balance.credits} credits, but need ${cost}. ` +
        `Credits will reset on ${balance.next_reset.toLocaleDateString()}.`
      );
    }
    
    try {
      const apiKey = this.getApiKey();
      
      // –°—Ç–≤–æ—Ä—é—î–º–æ –∑–∞–ø–∏—Å –≤ –ë–î
      const generation = new this.aiGenerationModel({
        id: generationId,
        user_id: userId || 'anonymous',
        type: 'text',
        prompt,
        parameters: { tone, length },
        status: 'processing',
        created_at: new Date(),
      });
      await generation.save();

      // –§–æ—Ä–º—É—î–º–æ —Å–∏—Å—Ç–µ–º–Ω–∏–π –ø—Ä–æ–º–ø—Ç –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Ç–æ–Ω—É
      const toneInstructions = {
        professional: 'Write in a professional, business-like tone.',
        friendly: 'Write in a warm, friendly, and approachable tone.',
        casual: 'Write in a casual, conversational tone.',
        formal: 'Write in a formal, official tone.',
        humorous: 'Write in a light-hearted, humorous tone.'
      };

      const lengthInstructions = {
        short: 'Keep it brief (1-2 sentences).',
        medium: 'Write 3-5 sentences.',
        long: 'Write a detailed response (6-10 sentences).'
      };

      const systemPrompt = `You are a creative content writer for social media. ${toneInstructions[tone] || toneInstructions.professional} ${lengthInstructions[length] || lengthInstructions.medium} Generate 3 different variations of the content.`;

      // –í–∏–∫–ª–∏–∫–∞—î–º–æ OpenRouter API (–ø—Ä–∞—Ü—é—î –∑ OpenAI –º–æ–¥–µ–ª—è–º–∏)
      console.log('üîÑ Calling OpenRouter API for text generation...');
      
      const response = await lastValueFrom(
        this.httpService.post(
          'https://openrouter.ai/api/v1/chat/completions',
          {
            model: 'openai/gpt-3.5-turbo',
            messages: [
              { role: 'system', content: systemPrompt },
              { role: 'user', content: prompt }
            ],
            max_tokens: length === 'long' ? 500 : length === 'medium' ? 300 : 150,
            n: 3,
            temperature: 0.8,
          },
          {
            headers: {
              'Authorization': `Bearer ${apiKey}`,
              'Content-Type': 'application/json',
            },
          }
        )
      );

      console.log('üì¶ OpenRouter response status:', response.status);
      console.log('üì¶ OpenRouter response data:', JSON.stringify(response.data, null, 2));

      // –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
      if (!response.data || !response.data.choices || response.data.choices.length === 0) {
        throw new InternalServerErrorException('Invalid response from OpenRouter API');
      }

      const variants = response.data.choices.map((choice: any) => 
        choice.message?.content?.trim() || ''
      ).filter(v => v.length > 0);

      if (variants.length === 0) {
        throw new InternalServerErrorException('No text variants generated');
      }

      console.log(`‚úçÔ∏è Generated ${variants.length} text variants`);

      // –û–Ω–æ–≤–ª—é—î–º–æ –∑–∞–ø–∏—Å –≤ –ë–î
      await this.aiGenerationModel.updateOne(
        { id: generationId },
        { 
          $set: { 
            result_variants: variants,
            status: 'completed',
            completed_at: new Date()
          } 
        }
      );

      // –°–ø–∏—Å—É—î–º–æ –∫—Ä–µ–¥–∏—Ç–∏ –ø—ñ—Å–ª—è —É—Å–ø—ñ—à–Ω–æ—ó –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
      const creditsRemaining = await this.aiCreditsService.deductCredits(
        userId, 
        cost, 
        'text_generation'
      );

      const result = { 
        variants, 
        generation_id: generationId,
        credits_remaining: creditsRemaining
      };

      console.log(`‚úÖ Text generation completed: ${generationId}, Credits remaining: ${creditsRemaining}`);
      console.log('üì§ Returning to frontend:', JSON.stringify(result, null, 2));

      return result;

    } catch (error) {
      console.error('‚ùå AI text generation error:', error);
      console.error('‚ùå Error response:', error.response?.data);
      console.error('‚ùå Error status:', error.response?.status);
      
      // –û–Ω–æ–≤–ª—é—î–º–æ —Å—Ç–∞—Ç—É—Å –Ω–∞ failed
      await this.aiGenerationModel.updateOne(
        { id: generationId },
        { 
          $set: { 
            status: 'failed',
            error_message: error.message,
            completed_at: new Date()
          } 
        }
      );

      const errorMessage = error.response?.data?.error?.message 
        || error.response?.data?.message
        || error.message 
        || 'Unknown error';

      throw new InternalServerErrorException(
        `AI text generation failed: ${errorMessage}`
      );
    }
  }

  async generateImage(
    prompt: string, 
    width: number = 1024, 
    height: number = 1024, 
    userId: string
  ): Promise<{ status: string; generation_id: string; image_id?: string; image_url?: string; credits_remaining: number }> {
    const generationId = this.generateId();
    const cost = this.aiCreditsService.getCost('image');
    
    // –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –±–∞–ª–∞–Ω—Å
    const hasCredits = await this.aiCreditsService.checkCredits(userId, cost);
    if (!hasCredits) {
      const balance = await this.aiCreditsService.getBalance(userId);
      throw new BadRequestException(
        `Insufficient AI credits. You have ${balance.credits} credits, but need ${cost}. ` +
        `Credits will reset on ${balance.next_reset.toLocaleDateString()}.`
      );
    }
    
    try {
      const apiKey = this.getApiKey();
      
      // –°—Ç–≤–æ—Ä—é—î–º–æ –∑–∞–ø–∏—Å –≤ –ë–î
      const generation = new this.aiGenerationModel({
        id: generationId,
        user_id: userId,
        type: 'image',
        prompt,
        parameters: { width, height },
        status: 'processing',
        created_at: new Date(),
      });
      await generation.save();

      // –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ä–æ–∑–º—ñ—Ä –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è (DALL-E –ø—ñ–¥—Ç—Ä–∏–º—É—î —Ç—ñ–ª—å–∫–∏ –ø–µ–≤–Ω—ñ —Ä–æ–∑–º—ñ—Ä–∏)
      let size = '1024x1024'; // default
      if (width === 1024 && height === 1792) {
        size = '1024x1792';
      } else if (width === 1792 && height === 1024) {
        size = '1792x1024';
      }

      console.log(`üé® Generating image with prompt: "${prompt.substring(0, 50)}..."`);

      // –í–∏–∫–ª–∏–∫–∞—î–º–æ OpenRouter API –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∑–æ–±—Ä–∞–∂–µ–Ω—å
      // –ü—Ä–∏–º—ñ—Ç–∫–∞: DALL-E –º–æ–∂–µ –±—É—Ç–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–º —á–µ—Ä–µ–∑ OpenRouter
      const response = await lastValueFrom(
        this.httpService.post(
          'https://openrouter.ai/api/v1/images/generations',
          {
            model: 'openai/dall-e-3',
            prompt,
            n: 1,
            size,
            quality: 'standard',
            response_format: 'url',
          },
          {
            headers: {
              'Authorization': `Bearer ${apiKey}`,
              'Content-Type': 'application/json',
            },
          }
        )
      );

      const imageUrl = response.data.data[0].url;
      
      // –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
      const imageResponse = await lastValueFrom(
        this.httpService.get(imageUrl, { responseType: 'stream' })
      );

      const mediaId = this.generateId();
      const filename = `ai_generated_${mediaId}.png`;
      const filePath = join(this.uploadDir, filename);

      // –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ñ–∞–π–ª
      await pump(imageResponse.data, createWriteStream(filePath));

      // –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ Media collection
      const media = new this.mediaModel({
        id: mediaId,
        user_id: userId,
        filename: `AI Generated: ${prompt.substring(0, 30)}...`,
        content_type: 'image/png',
        size: 0, // –†–æ–∑–º—ñ—Ä –±—É–¥–µ –≤–∏–∑–Ω–∞—á–µ–Ω–æ –ø—ñ–∑–Ω—ñ—à–µ
        file_path: filePath,
        created_at: new Date(),
      });
      await media.save();

      // –û–Ω–æ–≤–ª—é—î–º–æ –∑–∞–ø–∏—Å –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
      await this.aiGenerationModel.updateOne(
        { id: generationId },
        { 
          $set: { 
            result_image_url: `/api/media/${mediaId}`,
            result_media_id: mediaId,
            status: 'completed',
            completed_at: new Date()
          } 
        }
      );

      // –°–ø–∏—Å—É—î–º–æ –∫—Ä–µ–¥–∏—Ç–∏ –ø—ñ—Å–ª—è —É—Å–ø—ñ—à–Ω–æ—ó –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
      const creditsRemaining = await this.aiCreditsService.deductCredits(
        userId, 
        cost, 
        'image_generation'
      );

      console.log(`‚úÖ Image generation completed: ${generationId}, media: ${mediaId}, Credits remaining: ${creditsRemaining}`);

      return {
        status: 'completed',
        generation_id: generationId,
        image_id: mediaId,
        image_url: `/api/media/${mediaId}`,
        credits_remaining: creditsRemaining
      };

    } catch (error) {
      console.error('AI image generation error:', error);
      
      // –û–Ω–æ–≤–ª—é—î–º–æ —Å—Ç–∞—Ç—É—Å –Ω–∞ failed
      await this.aiGenerationModel.updateOne(
        { id: generationId },
        { 
          $set: { 
            status: 'failed',
            error_message: error.message,
            completed_at: new Date()
          } 
        }
      );

      throw new InternalServerErrorException(
        `AI image generation failed: ${error.response?.data?.error?.message || error.message}`
      );
    }
  }

  async getUserGenerations(userId: string, type?: string, page: number = 1, limit: number = 20) {
    const query: any = { user_id: userId };
    if (type) {
      query.type = type;
    }
    
    const skip = (page - 1) * limit;
    
    const [generations, total] = await Promise.all([
      this.aiGenerationModel
        .find(query, { _id: 0, __v: 0 })
        .sort({ created_at: -1 })
        .skip(skip)
        .limit(limit)
        .exec(),
      this.aiGenerationModel.countDocuments(query)
    ]);
    
    return {
      generations,
      pagination: {
        page,
        limit,
        total,
        totalPages: Math.ceil(total / limit)
      }
    };
  }

  async getGeneration(userId: string, generationId: string) {
    const generation = await this.aiGenerationModel.findOne(
      { id: generationId, user_id: userId },
      { _id: 0, __v: 0 }
    ).exec();
    
    if (!generation) {
      throw new InternalServerErrorException('Generation not found');
    }
    
    return generation;
  }

  private generateId(): string {
    return randomUUID();
  }
}